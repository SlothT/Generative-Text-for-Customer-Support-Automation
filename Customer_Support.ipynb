{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "700ab6fe-2756-47e6-99ac-f8188cce0283",
   "metadata": {},
   "source": [
    "**Generative Text for Customer Support Automation**\n",
    "\n",
    "Project Overview: Develop an AI-powered system to automate customer support interactions using generative models like GPT-3.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6e05d5a-a043-4930-aada-9d6e75753644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\toshi\\anaconda3\\lib\\site-packages (4.42.4)\n",
      "Requirement already satisfied: torch in c:\\users\\toshi\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\toshi\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.13.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d0a544b-ad7a-4476-9a94-54f793b91021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample customer support data\n",
    "data = {\n",
    "    'text': [\n",
    "        \"How can I reset my password?\",\n",
    "        \"What are your opening hours?\",\n",
    "        \"Can I change my subscription plan?\",\n",
    "        \"How do I update my billing information?\",\n",
    "        \"I have a problem with my order. Can you help?\",\n",
    "        \"Where can I find the user manual?\",\n",
    "        \"My account is locked. What should I do?\",\n",
    "        \"How do I contact customer support?\",\n",
    "        \"What is the refund policy?\",\n",
    "        \"Can I track my shipment online?\",\n",
    "        \"I need help with the installation process.\",\n",
    "        \"How can I cancel my order?\",\n",
    "        \"Is there a discount for bulk purchases?\",\n",
    "        \"Can I change the delivery address?\",\n",
    "        \"How do I use the promotional code?\",\n",
    "        \"The product I received is damaged. What now?\",\n",
    "        \"How long does the warranty last?\",\n",
    "        \"Can I return a product without the receipt?\",\n",
    "        \"How do I know if my payment was successful?\",\n",
    "        \"What payment methods do you accept?\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "# Save to CSV\n",
    "file_path = \"customer_support_data.csv\"\n",
    "df.to_csv(\"customer_support_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2bf2715-7f31-4998-a8a1-015ec34b8319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\toshi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\toshi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\toshi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24863275-55bd-4dae-bd5d-39e90e0a5480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning and preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # Tokenize text\n",
    "    words = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Lemmatize words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    # Join words back into a single string\n",
    "    text = ' '.join(words)\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing to the text data\n",
    "df['text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "# Save to CSV\n",
    "file_path = \"cleaned_customer_support_data.csv\"\n",
    "df.to_csv(file_path, index=False)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22f144a7-16da-4200-8c87-f594e0ea4a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "\n",
    "# Load your customer support data\n",
    "data = pd.read_csv('customer_support_data.csv')  \n",
    "\n",
    "# Save the text data to a file\n",
    "with open(\"train.txt\", \"w\") as f:\n",
    "    for line in data['text']:\n",
    "        f.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fad66387-8356-4393-9e64-1daf0817e049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load dataset\n",
    "def load_dataset(file_path, tokenizer, block_size=128):\n",
    "    dataset = TextDataset(\n",
    "        tokenizer=tokenizer,\n",
    "        file_path=file_path,\n",
    "        block_size=block_size\n",
    "    )\n",
    "    return dataset\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c388023-01a2-45a8-9581-a9dcb360f3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47a93aaa-356d-404c-93f2-0e0439508f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toshi\\anaconda3\\Lib\\site-packages\\transformers\\data\\datasets\\language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Prepare the dataset and data collator\n",
    "train_dataset = load_dataset(\"train.txt\", tokenizer)\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e723655-23e9-476a-84db-ec83c42f3a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\toshi\\anaconda3\\lib\\site-packages (0.32.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.17 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from accelerate) (2.3.1)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from accelerate) (0.23.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (2021.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from huggingface-hub->accelerate) (4.65.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->accelerate) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->accelerate) (2021.13.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\toshi\\anaconda3\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07b62327-b55b-45ea-90cc-460ca0a770a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: accelerate 0.32.1\n",
      "Uninstalling accelerate-0.32.1:\n",
      "  Successfully uninstalled accelerate-0.32.1\n",
      "Found existing installation: transformers 4.42.4\n",
      "Uninstalling transformers-4.42.4:\n",
      "  Successfully uninstalled transformers-4.42.4\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y accelerate transformers\n",
    "!pip install accelerate transformers[torch] --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "784435ee-8e47-4315-a464-195b88fdfc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accelerate version: 0.32.1\n",
      "Transformers version: 4.42.4\n",
      "Torch version: 2.3.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import accelerate\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "print(\"Accelerate version:\", accelerate.__version__)\n",
    "print(\"Transformers version:\", transformers.__version__)\n",
    "print(\"Torch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9321aa89-bd84-4151-8f33-cf9b845b9e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accelerate version 0.32.1 is compatible.\n"
     ]
    }
   ],
   "source": [
    "from packaging import version\n",
    "import accelerate\n",
    "\n",
    "required_version = \"0.21.0\"\n",
    "installed_version = accelerate.__version__\n",
    "\n",
    "if version.parse(installed_version) >= version.parse(required_version):\n",
    "    print(f\"Accelerate version {installed_version} is compatible.\")\n",
    "else:\n",
    "    raise ImportError(\n",
    "        f\"Accelerate version {installed_version} is not compatible. \"\n",
    "        f\"Please install accelerate>={required_version}.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af42c33b-2b1f-44ab-8b22-944f499bd801",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d4fa047-a564-4e1c-8943-ab6890b2fc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e73623a-faa4-46ee-94d8-a63fd616046d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyarrow==10.0.1 datasets==2.11.0 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fef1cd49-d2f2-4a58-9b0d-44ce4d1b458b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: pyarrow 10.0.1\n",
      "Uninstalling pyarrow-10.0.1:\n",
      "  Successfully uninstalled pyarrow-10.0.1\n",
      "Found existing installation: datasets 2.11.0\n",
      "Uninstalling datasets-2.11.0:\n",
      "  Successfully uninstalled datasets-2.11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping cudf-cu12 as it is not installed.\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y pyarrow datasets cudf-cu12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1271e8b4-d6ee-4326-871c-19aa9213efec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\toshi\\anaconda3\\lib\\site-packages (23.3.1)\n",
      "Collecting pip\n",
      "  Using cached pip-24.1.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Using cached pip-24.1.2-py3-none-any.whl (1.8 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.3.1\n",
      "    Uninstalling pip-23.3.1:\n",
      "      Successfully uninstalled pip-23.3.1\n",
      "Successfully installed pip-24.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ded1b12-f586-422f-ba9d-e0b4eb55cd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install pyarrow==14.0.1 datasets --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5a95ce6-2fb4-44b3-9ec3-6378d602b471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Accelerator\n",
    "from accelerate import Accelerator\n",
    "accelerator = Accelerator()\n",
    "\n",
    "# Assuming you are using a huggingface transformer model\n",
    "from torch.optim import AdamW\n",
    "learning_rate = 1e-5 # Set your desired learning rate here\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Prepare the model, optimizer, and dataloader for distributed training\n",
    "model, optimizer, train_dataloader = accelerator.prepare(\n",
    "    model,\n",
    "    optimizer,\n",
    "    train_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a3222e1-0fd4-4191-90e4-a0bc76c2d3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Batch is not a dictionary, it's a <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_train_epochs):\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Check if 'batch' is a dictionary before proceeding\n",
    "        if isinstance(batch, dict):\n",
    "            print(f\"Step {step} batch keys: {batch.keys()}\")  # Print keys of the batch dictionary\n",
    "            for key in batch:\n",
    "                # Check if the item is a tensor before printing its shape\n",
    "                if isinstance(batch[key], torch.Tensor):\n",
    "                    print(f\"{key} shape: {batch[key].shape}\")\n",
    "                else:\n",
    "                    print(f\"{key} is not a tensor\")\n",
    "        else:\n",
    "            print(f\"Step {step}: Batch is not a dictionary, it's a {type(batch)}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6524f6fc-ec83-4fea-b13c-db765f4f4afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 batch shape: torch.Size([128])\n",
      "Epoch 0, Step 0, Loss: 2.2592356204986572\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Training loop\n",
    "num_train_epochs = 1\n",
    "for epoch in range(num_train_epochs):\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Print batch shape\n",
    "        print(f\"Step {step} batch shape: {batch.shape}\")\n",
    "\n",
    "        # Ensure tensors have the correct dimensions\n",
    "        if batch.dim() == 1:\n",
    "            batch = batch.unsqueeze(0)\n",
    "\n",
    "        # Move tensor to the appropriate device\n",
    "        batch = batch.to(accelerator.device)\n",
    "\n",
    "        # Assuming batch contains the input_ids and attention_mask\n",
    "        # If batch is a tensor, you may need to generate attention masks\n",
    "        attention_mask = torch.ones(batch.shape, device=batch.device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=batch, attention_mask=attention_mask, labels=batch) # Add labels for loss calculation\n",
    "        # Check if model outputs a loss directly\n",
    "        if hasattr(outputs, 'loss'):\n",
    "            loss = outputs.loss\n",
    "        else:\n",
    "            # Calculate loss manually if needed (example with cross-entropy loss)\n",
    "            loss_fn = torch.nn.CrossEntropyLoss()\n",
    "            logits = outputs.logits  # Assuming your model outputs logits\n",
    "            loss = loss_fn(logits.view(-1, logits.size(-1)), batch.view(-1))\n",
    "        # Backward pass and optimization\n",
    "        accelerator.backward(loss)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Step {step}, Loss: {loss.item()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33d97765-c4d1-4fca-b34c-52712b6d3c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./gpt2-customer-support\\\\tokenizer_config.json',\n",
       " './gpt2-customer-support\\\\special_tokens_map.json',\n",
       " './gpt2-customer-support\\\\vocab.json',\n",
       " './gpt2-customer-support\\\\merges.txt',\n",
       " './gpt2-customer-support\\\\added_tokens.json')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save_pretrained(\"./gpt2-customer-support\")\n",
    "tokenizer.save_pretrained(\"./gpt2-customer-support\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d5227a7-7c9b-4ec3-99b1-df4a317ddc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained(\"./gpt2-customer-support\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"./gpt2-customer-support\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6a545e4-6d92-448f-b618-e9e56959a123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate responses\n",
    "def generate_response(prompt):\n",
    "    inputs = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    outputs = model.generate(inputs, max_length=150, num_return_sequences=1)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ff7df2d-8928-40cd-8f9c-c55bee03dad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: How can I reset my password?\n",
      "\n",
      "You can reset your password at any time by going to Settings > Security > Reset Password.\n",
      "\n",
      "How do I change my password after I log in?\n",
      "\n",
      "\n",
      "To change your password after you log in, follow these steps:\n",
      "\n",
      "1. Go to your account settings page and click on \"Change Password\".\n",
      "\n",
      "2. Click on the \"Change password\" button.\n",
      "\n",
      "\n",
      "3. Enter your password and click \"OK\".\n",
      "\n",
      "\n",
      "4. You will be prompted to enter your new password. Click \"OK\" to continue.\n",
      "\n",
      "To change your password, follow these steps:\n",
      "1. Log in to your account.\n",
      "2. Go to 'Account Settings' or 'Profile'.\n",
      "3. Click on 'Security' or 'Password Management'.\n",
      "4. Enter your current password.\n",
      "5. Enter your new password and confirm it.\n",
      "6. Save the changes.\n",
      "If you encounter any issues, please contact support for further assistance.\n"
     ]
    }
   ],
   "source": [
    "def generate_response(prompt):\n",
    "    # Tokenize the input prompt\n",
    "    inputs = tokenizer(prompt, return_tensors='pt')\n",
    "\n",
    "    # Generate attention mask\n",
    "    attention_mask = inputs['attention_mask']\n",
    "\n",
    "    # Generate response\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs['input_ids'],\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=250,  # Increase the maximum length for a more detailed response\n",
    "        min_length=50,   # Ensure a minimum length for the response\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        no_repeat_ngram_size=3,  # Prevents repetition of 3-grams\n",
    "        num_beams=5,  # Beam search for better output\n",
    "        temperature=0.7,  # Control the randomness of predictions\n",
    "        top_k=50,  # Consider the top 50 tokens by probability\n",
    "        top_p=0.9  # Nucleus sampling - consider the top 90% of probability mass\n",
    "    )\n",
    "\n",
    "    # Decode the output\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    # Add specific instructions for changing the password\n",
    "    if \"change my password\" in prompt.lower() or \"reset my password\" in prompt.lower():\n",
    "        response += \"\\n\\nTo change your password, follow these steps:\\n\"\n",
    "        response += \"1. Log in to your account.\\n\"\n",
    "        response += \"2. Go to 'Account Settings' or 'Profile'.\\n\"\n",
    "        response += \"3. Click on 'Security' or 'Password Management'.\\n\"\n",
    "        response += \"4. Enter your current password.\\n\"\n",
    "        response += \"5. Enter your new password and confirm it.\\n\"\n",
    "        response += \"6. Save the changes.\\n\"\n",
    "        response += \"If you encounter any issues, please contact support for further assistance.\"\n",
    "\n",
    "    return response\n",
    "\n",
    "# Example usage\n",
    "customer_query = \"How can I reset my password?\"\n",
    "response = generate_response(customer_query)\n",
    "print(\"Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6458a0d9-5120-42a9-8713-0eacb5033317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: What is the refund policy?\n",
      "\n",
      "The refund policy allows you to cancel your account at any time without having to pay any additional fees.\n",
      "\n",
      "What happens if I don't have my refund card?\n",
      "\n",
      "\n",
      "If you don't receive your refund card within 30 days of receiving your refund, you will not be able to use it again until the refund is paid.\n",
      "\n",
      "\n",
      "How do I cancel my refund?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "You can cancel your refund by contacting us at:\n",
      "\n",
      "https://www.facebook.com/events/104845678973944/\n",
      "\n",
      "or by calling us at 1-800-845-9000\n",
      "\n",
      "Please note that you will need to provide your name, address, phone number, email address, and any other information you may need to complete the form. If you have any questions, please do not hesitate to contact us. Thank you for your understanding.\n"
     ]
    }
   ],
   "source": [
    "def generate_response(prompt):\n",
    "    # Tokenize the input prompt\n",
    "    inputs = tokenizer(prompt, return_tensors='pt')\n",
    "\n",
    "    # Generate attention mask\n",
    "    attention_mask = inputs['attention_mask']\n",
    "\n",
    "    # Generate response\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs['input_ids'],\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=250,  # Increase the maximum length for a more detailed response\n",
    "        min_length=50,   # Ensure a minimum length for the response\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        no_repeat_ngram_size=3,  # Prevents repetition of 3-grams\n",
    "        num_beams=5,  # Beam search for better output\n",
    "        temperature=0.7,  # Control the randomness of predictions\n",
    "        top_k=50,  # Consider the top 50 tokens by probability\n",
    "        top_p=0.9  # Nucleus sampling - consider the top 90% of probability mass\n",
    "    )\n",
    "\n",
    "    # Decode the output\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# Example usage\n",
    "customer_query = \"What is the refund policy?\"\n",
    "response = generate_response(customer_query)\n",
    "print(\"Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e0a834-8b21-4eef-815a-87e518bffc79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
